{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing Demo\n",
    "This notebook explains step by step how raw depth maps are refined and cleaned up.\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mit_semseg.utils import colorEncode\n",
    "from megadepth.postprocessing.image_processing import erode_and_remove, filter_unstable_depths\n",
    "from megadepth.postprocessing.semantic_filtering import get_mask, apply_semantic_filtering\n",
    "from megadepth.postprocessing.semantic_segmentation import get_segmentation_model\n",
    "from megadepth.utils.io import load_depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = scipy.io.loadmat(\"color150.mat\")[\"colors\"]\n",
    "\n",
    "def plot_images(images: list, titles: list) -> None:\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        fig.add_subplot(1, len(images), i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(images[i],interpolation='nearest')\n",
    "        plt.title(titles[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to change the variables in the following cell to try out other images and depth maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model_dir = os.path.join(\"..\", \"data\", \"south-building\", \"dense\", \"colmap\")\n",
    "image_fn = \"P1180218.JPG\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Processing I\n",
    "As a first step, we filter unstable depth values by. A depth value is thereby removed if it deviates too much from the median depth value of its local neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(os.path.join(dense_model_dir, \"images\", image_fn)).convert(\"RGB\")\n",
    "depth_map_0 = load_depth_map(os.path.join(dense_model_dir, \"stereo\", \"depth_maps\", f\"{image_fn}.geometric.bin\"))\n",
    "depth_map_1 = filter_unstable_depths(depth_map_0)\n",
    "\n",
    "plot_images([image, depth_map_0, depth_map_1, depth_map_0 - depth_map_1], [\"Image\", \"Raw Depth Map\", \"Filtered Depth Map\", \"Difference\"])\n",
    "crop = np.s_[-250:,-1300:-1000]\n",
    "plot_images([np.array(image)[crop], depth_map_0[crop], depth_map_1[crop], depth_map_0[crop] - depth_map_1[crop]], [\"Image (Crop)\", \"Raw Depth Map (Crop)\", \"Filtered Depth Map (Crop)\", \"Difference\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Segmentation\n",
    "Next, we extract a segmentation map from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_segmentation_model(\"hrnet\")\n",
    "segmentation_map = model.get_segmentation_map(image)\n",
    "\n",
    "plot_images([image, colorEncode(segmentation_map, colors)], [\"Image\", \"Segmentation Map\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Filtering\n",
    "\n",
    "Using the segmentation map, we can extract different types of masks. Below are some examples.\n",
    "\n",
    "*Note: Our label IDs are 0-indexed (just like in the segmentation maps) while the label IDs in the [ADE20K Google Sheets](https://docs.google.com/spreadsheets/d/1se8YEtb2detS7OuPE86fXGyD269pMycAWe2mtKUj2W8/edit?usp=sharing) are 1-indexed.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_mask = get_mask(segmentation_map, \"sky\")\n",
    "background_mask = get_mask(segmentation_map, \"background\")\n",
    "creature_mask = get_mask(segmentation_map, \"human\")\n",
    "tree_mask = get_mask(segmentation_map, \"tree\")\n",
    "plant_mask = get_mask(segmentation_map, \"plant\")\n",
    "\n",
    "plot_images([image, sky_mask, background_mask], [\"Image\", \"Sky Mask\", \"Background Mask\"])\n",
    "plot_images([creature_mask, tree_mask, plant_mask], [\"Human Mask\", \"Tree Mask\", \"Plant Mask\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the different masks, we can apply semantic filtering. For that, we set the depth values in each connected component of certain foreground masks to 0 if the fraction of valid depth values in the component is too small. Moreover, we remove all depth values from the sky region as well as from certain foreground classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map_2 = apply_semantic_filtering(depth_map_1, segmentation_map)\n",
    "plot_images([depth_map_1, depth_map_2, depth_map_1 - depth_map_2], [\"Before\", \"After\", \"Difference\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Processing II\n",
    "Finally, we apply morphological erosion and remove small connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map_3 = erode_and_remove(depth_map_2)\n",
    "plot_images([depth_map_2, depth_map_3, depth_map_2 - depth_map_3], [\"Before\", \"After\", \"Difference\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
