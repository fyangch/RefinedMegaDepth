{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import scripts.create_overview as create_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"data_path\": \"/Volumes/Extreme_SSD/MegaDepth/scenes/\",\n",
    "    # \"data_path\": \"../data/scenes/\",\n",
    "    \"output\": \"../data/metrics_overview.json\",\n",
    "}\n",
    "\n",
    "# convert to argparse.Namespace\n",
    "args = type(\"Namespace\", (object,), args)\n",
    "\n",
    "\n",
    "create_overview.main(args)\n",
    "\n",
    "metrics = json.load(open(\"../data/overview.json\"))\n",
    "\n",
    "scenes = list(metrics.keys())\n",
    "print(f\"Loaded {len(scenes)} scenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = \"0229\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metrics, scene):\n",
    "    keys = [\n",
    "        \"n_reg_images\", \n",
    "        \"perc_reg_images\", \n",
    "        \"mean_reprojection_error\", \n",
    "        \"n_observations\", \n",
    "        \"mean_obs_per_reg_image\", \n",
    "        \"mean_track_length\",\n",
    "        \"mean_overlap\"\n",
    "    ]\n",
    "    \n",
    "    labels = []\n",
    "    for m in metrics[scene]:\n",
    "        if \"model_name\" in m.keys():\n",
    "            labels.append(m[\"model_name\"])\n",
    "        else:\n",
    "            labels.append(f\"{m['features']}-{m['matcher']}\")\n",
    "\n",
    "    fig, ax = plt.subplots(4, 2, figsize=(30, 30))\n",
    "    colors = [\"red\", \"green\", \"blue\", \"orange\", \"purple\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\"]\n",
    "    \n",
    "    ids = np.argsort(labels)\n",
    "    labels = [labels[i] for i in ids]\n",
    "    \n",
    "    for i, metric in enumerate(keys):\n",
    "        values = [m[metric] for m in metrics[scene]]\n",
    "\n",
    "        values = [values[i] for i in ids]\n",
    "\n",
    "        ax[i // 2, i % 2].bar(labels, values)\n",
    "\n",
    "        \n",
    "        # rotate labels\n",
    "        for tick in ax[i // 2, i % 2].get_xticklabels():\n",
    "            tick.set_rotation(10)\n",
    "        \n",
    "        ax[i // 2, i % 2].set_title(metric)\n",
    "        \n",
    "    \n",
    "    plt.suptitle(f\"Scene {scene}-sparse\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(metrics, scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table\n",
    "\n",
    "# model name & n_images & reg images & mean reprojection error & n observations & mean obs per reg image & mean track length & mean overlap\n",
    "\n",
    "print(\"model name & n_images & reg images & mean reprojection error & n observations & mean obs per reg image & mean track length & mean overlap\")\n",
    "for m in metrics[scene]:\n",
    "    if \"model_name\" in m.keys():\n",
    "        model_name = m[\"model_name\"]\n",
    "    else:\n",
    "        model_name = f\"{m['features']}-{m['matcher']}\"\n",
    "    \n",
    "    print(f\"{model_name} & {m['n_images']} & {m['n_reg_images']} & {m['mean_reprojection_error']:.2f} & {m['n_observations']} & {m['mean_obs_per_reg_image']:.2f} & {m['mean_track_length']:.2f} & {m['mean_overlap']:.2f} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = metrics[scene][0][\"n_images\"]\n",
    "\n",
    "base_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"baseline\")[\"n_reg_images\"]\n",
    "base_perc_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"baseline\")[\"perc_reg_images\"]\n",
    "\n",
    "try:\n",
    "    super_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"superpoint_max-superglue-netvlad-50\")[\"n_reg_images\"]\n",
    "    super_perc_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"superpoint_max-superglue-netvlad-50\")[\"perc_reg_images\"]\n",
    "    super_name = \"superpoint_max-superglue-netvlad-50\"\n",
    "except Exception as e:\n",
    "    try:\n",
    "        super_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"superpoint_max-superglue-exhaustive-50\")[\"n_reg_images\"]\n",
    "        super_perc_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"superpoint_max-superglue-exhaustive-50\")[\"perc_reg_images\"]\n",
    "        super_name = \"superpoint_max-superglue-exhaustive-50\"\n",
    "    except Exception as e:\n",
    "        super_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"superpoint_max-superglue-exhaustive\")[\"n_reg_images\"]\n",
    "        super_perc_reg_images = next(m for m in metrics[scene] if m[\"model_name\"] == \"superpoint_max-superglue-exhaustive\")[\"perc_reg_images\"]\n",
    "        super_name = \"superpoint_max-superglue-exhaustive\"\n",
    "except:\n",
    "    raise ValueError(\"Could not find superpoint model\")\n",
    "\n",
    "\n",
    "print(f\"Num images: {n_images}\")\n",
    "print(f\"Baseline:   {base_reg_images} ({base_perc_reg_images:.2f}%)\")\n",
    "print(f\"Superpoint: {super_reg_images} ({super_perc_reg_images:2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_obs = next(m for m in metrics[scene] if m[\"model_name\"] == \"baseline\")[\"n_observations\"]\n",
    "super_obs = next(m for m in metrics[scene] if m[\"model_name\"] == super_name)[\"n_observations\"]\n",
    "\n",
    "print(\"Num observations\")\n",
    "print(f\"Baseline:         {base_obs}\")\n",
    "print(f\"Superpoint:       {super_obs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mean_obs = next(m for m in metrics[scene] if m[\"model_name\"] == \"baseline\")[\"mean_obs_per_reg_image\"]\n",
    "super_mean_obs = next(m for m in metrics[scene] if m[\"model_name\"] == super_name)[\"mean_obs_per_reg_image\"]\n",
    "\n",
    "print(\"Mean observations per registered image\")\n",
    "print(f\"Baseline:         {base_mean_obs}\")\n",
    "print(f\"Superpoint:       {super_mean_obs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pycolmap\n",
    "from hloc import visualization\n",
    "from hloc.utils import viz_3d\n",
    "\n",
    "data_path = Path(\"/Volumes/Extreme_SSD/MegaDepth/scenes/\")\n",
    "# data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(os.path.join(data_path, scene, \"sparse\", super_name))\n",
    "img_path = Path(os.path.join(data_path, scene, \"images\"))\n",
    "\n",
    "super_model = pycolmap.Reconstruction(model_path)\n",
    "\n",
    "super_track_lengths = [p.track.length() for p in super_model.points3D.values()]\n",
    "super_n_visible = [img.num_points3D() for img in super_model.images.values()]\n",
    "\n",
    "visualization.visualize_sfm_2d(super_model, img_path, color_by='visibility', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(super_model, img_path, color_by='depth', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(super_model, img_path, color_by='track_length', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(os.path.join(data_path, scene, \"sparse\", \"baseline\"))\n",
    "\n",
    "base_model = pycolmap.Reconstruction(model_path)\n",
    "\n",
    "base_track_lengths = [p.track.length() for p in base_model.points3D.values()]\n",
    "base_n_visible = [img.num_points3D() for img in base_model.images.values()]\n",
    "\n",
    "visualization.visualize_sfm_2d(base_model, img_path, color_by='visibility', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(base_model, img_path, color_by='depth', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_sfm_2d(base_model, img_path, color_by='track_length', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot num observations per image\n",
    "\n",
    "plt.hist(super_n_visible, bins=100, alpha=0.5, label=\"superpoint\")\n",
    "plt.hist(base_n_visible, bins=100, alpha=0.5, label=\"baseline\")\n",
    "\n",
    "plt.title(\"Num observations per image\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot track lengths\n",
    "\n",
    "plt.hist(super_track_lengths, bins=100, alpha=0.5, label=\"superpoint\", log=True)\n",
    "plt.hist(base_track_lengths, bins=100, alpha=0.5, label=\"baseline\", log=True)\n",
    "\n",
    "\n",
    "plt.title(\"Track lengths\")\n",
    "plt.xlabel(\"Track length\")\n",
    "plt.ylabel(\"Frequency (log scale)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Unregistered Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_path = Path(os.path.join(data_path, scene, \"sparse\", super_name))\n",
    "base_path = Path(os.path.join(data_path, scene, \"sparse\", \"baseline\"))\n",
    "\n",
    "super_model = pycolmap.Reconstruction(super_path)\n",
    "base_model = pycolmap.Reconstruction(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(img_path)\n",
    "print(f\"Scene {scene} has {len(images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_supermodel = [i.name for i in super_model.images.values()]\n",
    "images_basemodel = [i.name for i in base_model.images.values()]\n",
    "\n",
    "print(f\"Superpoint model has {len(images_supermodel)} images\")\n",
    "print(f\"Baseline model has {len(images_basemodel)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 25 random images that are not in the baseline model\n",
    "unregistered_images = np.random.choice([i for i in images if i not in images_basemodel], 25)\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, figsize=(30, 30))\n",
    "for i, image in enumerate(unregistered_images):\n",
    "    ax[i // 5, i % 5].imshow(plt.imread(os.path.join(img_path, image)))\n",
    "    in_supermodel = image in images_supermodel\n",
    "    ax[i // 5, i % 5].set_title(f\"{image} (in supermodel: {in_supermodel})\")\n",
    "    ax[i // 5, i % 5].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 25 random images that are not in the superpoint model\n",
    "unregistered_images = np.random.choice([i for i in images if i not in images_supermodel], 25)\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, figsize=(30, 30))\n",
    "for i, image in enumerate(unregistered_images):\n",
    "    ax[i // 5, i % 5].imshow(plt.imread(os.path.join(img_path, image)))\n",
    "    in_basemodel = image in images_basemodel\n",
    "    ax[i // 5, i % 5].set_title(f\"{image} (in basemodel: {in_basemodel})\")\n",
    "    ax[i // 5, i % 5].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import collections.abc as collections\n",
    "\n",
    "\n",
    "from hloc.utils.io import list_h5_names\n",
    "from hloc.utils.read_write_model import read_images_binary\n",
    "from hloc.utils.read_write_model import read_images_binary\n",
    "from hloc.utils.io import list_h5_names\n",
    "from hloc.utils.parsers import parse_image_lists\n",
    "\n",
    "db_descriptors = None\n",
    "# descriptors = Path(\"../data/0229/features/netvlad.h5\")\n",
    "descriptors = Path(os.path.join(data_path, scene, \"features\", \"netvlad.h5\"))\n",
    "num_matched = 100\n",
    "# output = Path(\"../data/retrieval.txt\")\n",
    "output = None\n",
    "query_prefix=None\n",
    "query_list=None\n",
    "db_prefix=None\n",
    "db_list=None\n",
    "db_model=None\n",
    "db_descriptors=None\n",
    "\n",
    "image_dir = os.path.join(data_path, scene, \"images\")\n",
    "\n",
    "def parse_names(prefix, names, names_all):\n",
    "    if prefix is not None:\n",
    "        if not isinstance(prefix, str):\n",
    "            prefix = tuple(prefix)\n",
    "        names = [n for n in names_all if n.startswith(prefix)]\n",
    "        if len(names) == 0:\n",
    "            raise ValueError(\n",
    "                f'Could not find any image with the prefix `{prefix}`.')\n",
    "    elif names is not None:\n",
    "        if isinstance(names, (str, Path)):\n",
    "            names = parse_image_lists(names)\n",
    "        elif isinstance(names, collections.Iterable):\n",
    "            names = list(names)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown type of image list: {names}.'\n",
    "                             'Provide either a list or a path to a list file.')\n",
    "    else:\n",
    "        names = names_all\n",
    "    return names\n",
    "\n",
    "def get_descriptors(names, path, name2idx=None, key='global_descriptor'):\n",
    "    if name2idx is None:\n",
    "        with h5py.File(str(path), 'r', libver='latest') as fd:\n",
    "            desc = [fd[n][key].__array__() for n in names]\n",
    "    else:\n",
    "        desc = []\n",
    "        for n in names:\n",
    "            with h5py.File(str(path[name2idx[n]]), 'r', libver='latest') as fd:\n",
    "                desc.append(fd[n][key].__array__())\n",
    "    return torch.from_numpy(np.stack(desc, 0)).float()\n",
    "\n",
    "if db_descriptors is None:\n",
    "    db_descriptors = descriptors\n",
    "if isinstance(db_descriptors, (Path, str)):\n",
    "    db_descriptors = [db_descriptors]\n",
    "name2db = {n: i for i, p in enumerate(db_descriptors)\n",
    "            for n in list_h5_names(p)}\n",
    "db_names_h5 = list(name2db.keys())\n",
    "query_names_h5 = list_h5_names(descriptors)\n",
    "\n",
    "if db_model:\n",
    "    images = read_images_binary(db_model / 'images.bin')\n",
    "    db_names = [i.name for i in images.values()]\n",
    "else:\n",
    "    db_names = parse_names(db_prefix, db_list, db_names_h5)\n",
    "if len(db_names) == 0:\n",
    "    raise ValueError('Could not find any database image.')\n",
    "query_names = parse_names(query_prefix, query_list, query_names_h5)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "db_desc = get_descriptors(db_names, db_descriptors, name2db)\n",
    "query_desc = get_descriptors(query_names, descriptors)\n",
    "sim = torch.einsum('id,jd->ij', query_desc.to(device), db_desc.to(device))\n",
    "\n",
    "# Avoid self-matching\n",
    "self = np.array(query_names)[:, None] == np.array(db_names)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.sum(sim > 0.2, dim=1) / sim.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = [\n",
    "    img for img in os.listdir(os.path.join(data_path, scene, \"images\")) \n",
    "    if img.endswith(\".jpg\") or img.endswith(\".JPG\") or img.endswith(\".png\")\n",
    "]\n",
    "\n",
    "r_img_names = []\n",
    "for key in super_model.images.values():\n",
    "    r_img_names.append(key.name)\n",
    "\n",
    "df = pd.DataFrame({'query': query_names, 'score': scores, \"registered\": False})\n",
    "df.set_index('query', inplace=True)\n",
    "df.registered = df.index.isin(r_img_names)\n",
    "df = df.sort_values(by=['registered', 'score'], ascending=[True, True])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.bar(df.index, df.score, color=df.registered.map({True: 'green', False: 'red'}))\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "plt.title(\"Rel. Number of Scores Above 0.2 in Retrieval Matrix\")\n",
    "\n",
    "plt.ylabel(\"Rel. Number of Scores Above 0.2\")\n",
    "plt.xlabel(\"Query Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top 25 unreigstered images\n",
    "\n",
    "cdf = df[~df.registered][:25]\n",
    "\n",
    "# revert order\n",
    "cdf = cdf.iloc[::-1]\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for i, (name, row) in enumerate(cdf.iterrows()):\n",
    "    ax[i // 5, i % 5].imshow(imread(os.path.join(image_dir, name)))\n",
    "    ax[i // 5, i % 5].set_title(f\"{100*row.score:.1f} %\")\n",
    "    ax[i // 5, i % 5].set_xticks([])\n",
    "    ax[i // 5, i % 5].set_yticks([])\n",
    "\n",
    "fig.suptitle(\"Unreigstered images with lowest scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = df[~df.registered][-25:]\n",
    "\n",
    "# revert order\n",
    "cdf = cdf.iloc[::-1]\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for i, (name, row) in enumerate(cdf.iterrows()):\n",
    "    ax[i // 5, i % 5].imshow(imread(os.path.join(image_dir, name)))\n",
    "    ax[i // 5, i % 5].set_title(f\"{100*row.score:.1f} %\")\n",
    "    ax[i // 5, i % 5].set_xticks([])\n",
    "    ax[i // 5, i % 5].set_yticks([])\n",
    "\n",
    "fig.suptitle(\"Unreigstered images with highest scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = df[df.registered][-25:]\n",
    "\n",
    "# revert order\n",
    "cdf = cdf.iloc[::-1]\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for i, (name, row) in enumerate(cdf.iterrows()):\n",
    "    ax[i // 5, i % 5].imshow(imread(os.path.join(image_dir, name)))\n",
    "    ax[i // 5, i % 5].set_title(f\"{100*row.score:.1f} %\")\n",
    "    ax[i // 5, i % 5].set_xticks([])\n",
    "    ax[i // 5, i % 5].set_yticks([])\n",
    "\n",
    "\n",
    "fig.suptitle(\"Reigstered images with highest scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = df[df.registered][:25]\n",
    "\n",
    "# revert order\n",
    "cdf = cdf.iloc[::-1]\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for i, (name, row) in enumerate(cdf.iterrows()):\n",
    "    ax[i // 5, i % 5].imshow(imread(os.path.join(image_dir, name)))\n",
    "    ax[i // 5, i % 5].set_title(f\"{100*row.score:.1f} %\")\n",
    "    ax[i // 5, i % 5].set_xticks([])\n",
    "    ax[i // 5, i % 5].set_yticks([])\n",
    "\n",
    "fig.suptitle(\"Reigstered images with lowest scores\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_path = os.path.join(data_path, scene, \"matches\", \"superpoint_max-superglue-netvlad-50.h5\")\n",
    "# matches_path = os.path.join(data_path, scene, \"matches\", \"superpoint_max-superglue-exhaustive.h5\")\n",
    "matches = h5py.File(matches_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_images = [img.name for img in super_model.images.values()]\n",
    "unreg_images = [img for img in img_names if img not in reg_images]\n",
    "\n",
    "print(f\"Number of registered images:   {len(reg_images)}\")\n",
    "print(f\"Number of unregistered images: {len(unreg_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reg reg\n",
    "from tqdm import tqdm\n",
    "\n",
    "key_to_idx_reg = {key: idx for idx, key in enumerate(reg_images)}\n",
    "key_to_idx_unreg = {key: idx for idx, key in enumerate(unreg_images)}\n",
    "\n",
    "counts_reg_reg = np.zeros((len(reg_images), len(reg_images)))\n",
    "for img1 in tqdm(reg_images):\n",
    "    if img1 in matches.keys():\n",
    "        for img2 in reg_images:\n",
    "            if img2 in matches[img1].keys():\n",
    "                counts_reg_reg[key_to_idx_reg[img1], key_to_idx_reg[img2]] = matches[img1][img2][\"matches0\"].shape[0]\n",
    "\n",
    "count_reg_unreg = np.zeros((len(reg_images), len(unreg_images)))\n",
    "for img1 in tqdm(reg_images):\n",
    "    if img1 in matches.keys():\n",
    "        for img2 in unreg_images:\n",
    "            if img2 in matches[img1].keys():\n",
    "                count_reg_unreg[key_to_idx_reg[img1], key_to_idx_unreg[img2]] = matches[img1][img2][\"matches0\"].shape[0]\n",
    "\n",
    "counts_unreg_unreg = np.zeros((len(unreg_images), len(unreg_images)))\n",
    "for img1 in tqdm(unreg_images):\n",
    "    if img1 in matches.keys():\n",
    "        for img2 in unreg_images:\n",
    "            if img2 in matches[img1].keys():\n",
    "                counts_unreg_unreg[key_to_idx_unreg[img1], key_to_idx_unreg[img2]] = matches[img1][img2][\"matches0\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = np.max([np.sum(counts_reg_reg==0), np.sum(counts_unreg_unreg==0), np.sum(count_reg_unreg==0)])\n",
    "max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(30, 20))\n",
    "\n",
    "size = 500\n",
    "\n",
    "rel_zeros = np.sum(counts_reg_reg==0) / counts_reg_reg.size\n",
    "ax[0, 0].imshow(np.log(counts_reg_reg+1)[:size, :size], cmap=\"gray\")\n",
    "ax[0, 0].set_title(f\"Registered - Registered ({rel_zeros*100:.2f} % zeros)\")\n",
    "ax[0, 0].set_ylabel(\"Registered images\")\n",
    "ax[0, 0].set_xlabel(\"Registered images\")\n",
    "\n",
    "ax[1, 0].hist(counts_reg_reg.flatten(), bins=100)\n",
    "ax[1, 0].set_yscale(\"log\")\n",
    "ax[1, 0].set_title(\"Registered - Registered\")\n",
    "ax[1, 0].set_ylabel(\"log(count)\")\n",
    "ax[1, 0].set_ylim(1, max_count)\n",
    "\n",
    "\n",
    "rel_zeros = np.sum(count_reg_unreg==0) / count_reg_unreg.size\n",
    "ax[0, 1].imshow(np.log(count_reg_unreg+1)[:size, :size], cmap=\"gray\")\n",
    "ax[0, 1].set_title(f\"Registered - Unregistered ({rel_zeros*100:.2f} % zeros)\")\n",
    "ax[0, 1].set_ylabel(\"Registered images\")\n",
    "ax[0, 1].set_xlabel(\"Unregistered images\")\n",
    "\n",
    "ax[1, 1].hist(count_reg_unreg.flatten(), bins=100)\n",
    "ax[1, 1].set_yscale(\"log\")\n",
    "ax[1, 1].set_title(\"Registered - Unregistered\")\n",
    "ax[1, 1].set_ylabel(\"log(count)\")\n",
    "ax[1, 1].set_ylim(1, max_count)\n",
    "\n",
    "\n",
    "rel_zeros = np.sum(counts_unreg_unreg==0) / counts_unreg_unreg.size\n",
    "ax[0, 2].imshow(np.log(counts_unreg_unreg+1)[:size, :size], cmap=\"gray\")\n",
    "ax[0, 2].set_title(f\"Unregistered - Unregistered ({rel_zeros*100:.2f} % zeros)\")\n",
    "ax[0, 2].set_ylabel(\"Unregistered images\")\n",
    "ax[0, 2].set_xlabel(\"Unregistered images\")\n",
    "\n",
    "ax[1, 2].hist(counts_unreg_unreg.flatten(), bins=100)\n",
    "ax[1, 2].set_yscale(\"log\")\n",
    "ax[1, 2].set_title(\"Unregistered - Unregistered\")\n",
    "ax[1, 2].set_ylabel(\"log(count)\")\n",
    "ax[1, 2].set_ylim(1, max_count)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_overlap_name = [m[\"overlap_fn\"] for m in metrics[scene] if m[\"model_name\"] == \"baseline\"][0]\n",
    "super_overlap_name = [m[\"overlap_fn\"] for m in metrics[scene] if m[\"model_name\"] == super_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sparse_overlap_matrix = np.load(os.path.join(data_path, scene, \"metrics\", \"baseline\", base_overlap_name))\n",
    "super_sparse_overlap_matrix = np.load(os.path.join(data_path, scene, \"metrics\", super_name, super_overlap_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(base_sparse_overlap_matrix)\n",
    "plt.title(\"Baseline overlap matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(super_sparse_overlap_matrix)\n",
    "plt.title(\"Superpoint overlap matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(super_sparse_overlap_matrix.flatten(), bins=100, alpha=0.5, label=\"superpoint\")\n",
    "plt.hist(base_sparse_overlap_matrix.flatten(), bins=100, alpha=0.5, label=\"baseline\")\n",
    "\n",
    "plt.ylim(0, 1_000_000)\n",
    "\n",
    "plt.title(\"Overlap histogram\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadepth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
