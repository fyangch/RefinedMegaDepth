{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import pycolmap\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"/Volumes/Extreme_SSD/MegaDepth\"\n",
    "\n",
    "scene = \"5018\"\n",
    "\n",
    "location = \"Colony on MathildenhÃ¶he, Darmstadt\"\n",
    "\n",
    "\n",
    "name = f\"{scene}-sfm-mvs\"\n",
    "base_name = \"baseline\"\n",
    "# base_name = \"superpoint_max-superglue-netvlad-50\"\n",
    "\n",
    "# super_name = \"loftr-netvlad-50-KA+BA\"\n",
    "# super_name = \"superpoint_max-superglue-netvlad-50-KA+BA\"\n",
    "# super_name = \"superpoint_max-superglue-netvlad-50\"\n",
    "# super_name = \"superpoint_max-superglue-exhaustive-KA+BA\"\n",
    "\n",
    "super_name = \"disk_lg+sift+splg\"\n",
    "\n",
    "\n",
    "base_sfm_movie = os.path.join(data, \"scenes\", scene, \"visualizations\", base_name, \"sfm.mp4\")\n",
    "super_sfm_movie = os.path.join(data, \"scenes\", scene, \"visualizations\", super_name, \"sfm.mp4\")\n",
    "\n",
    "base_mvs_movie = os.path.join(data, \"scenes\", scene, \"visualizations\", base_name, \"mvs.mp4\")\n",
    "super_mvs_movie = os.path.join(data, \"scenes\", scene, \"visualizations\", super_name, \"mvs.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = pycolmap.Reconstruction(os.path.join(data, \"scenes\", scene, \"sparse\", base_name))\n",
    "super_model = pycolmap.Reconstruction(os.path.join(data, \"scenes\", scene, \"sparse\", super_name))\n",
    "\n",
    "print(base_model.summary())\n",
    "print(super_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = os.listdir(os.path.join(data, \"scenes\", scene, \"images\"))\n",
    "num_images = len(num_images)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 5386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_txt(model: pycolmap.Reconstruction, num_images) -> str:\n",
    "    txt = f\"Number of registered images:   {model.num_reg_images():.0f}\\n\"\n",
    "    txt += f\"% of registered images:              {model.num_reg_images() / num_images * 100:.1f}%\\n\"\n",
    "    txt += f\"Number of points:                        {model.num_points3D():.0f}\\n\"\n",
    "    txt += f\"Mean observations per image:  {model.compute_mean_observations_per_reg_image():.1f}\\n\"\n",
    "    txt += f\"Mean track length:                       {model.compute_mean_track_length():.1f}\\n\"\n",
    "    txt += f\"Mean reprojection error:             {model.compute_mean_reprojection_error():.4f}\\n\"\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the videos as numpy arrays\n",
    "cap1 = cv2.VideoCapture(super_sfm_movie)\n",
    "cap2 = cv2.VideoCapture(super_mvs_movie)\n",
    "\n",
    "# get resolution\n",
    "width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = cap1.read()[1]\n",
    "frame2 = cap2.read()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "frame[:, :width//2, :] = frame1[:, :width//2, :]\n",
    "frame[:, width//2:, :] = frame2[:, width//2:, :]\n",
    "\n",
    "frame[:, width//2-1:width//2+1, :] = [0, 0, 0]\n",
    "\n",
    "# add text to the frame using PIL\n",
    "\n",
    "def add_text_to_frame(frame, location, base_model, super_model):\n",
    "    pil_frame = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(pil_frame)\n",
    "    font = ImageFont.truetype(\"Arial.ttf\", 20)\n",
    "\n",
    "    draw.text((10, 10), \"Structure from Motion\", font=font, fill=(0, 0, 0))\n",
    "    draw.text((width-180, 10), \"Multi-View Stereo\", font=font, fill=(0, 0, 0))\n",
    "    draw.text((10, height - 30), f\"{location}\", font=font, fill=(0, 0, 0))\n",
    "\n",
    "    # add model summary\n",
    "    # font = ImageFont.truetype(\"Arial.ttf\", 16)\n",
    "    # draw.text((10, 40), f\"{get_summary_txt(base_model, num_images)}\", font=font, fill=(0, 0, 0))\n",
    "    # draw.text((width-330, 40), f\"{get_summary_txt(super_model, num_images)}\", font=font, fill=(0, 0, 0))\n",
    "    return np.array(pil_frame)\n",
    "\n",
    "\n",
    "frame = add_text_to_frame(frame, location, base_model, super_model)\n",
    "\n",
    "\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "ax.imshow(frame)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the videos as numpy arrays\n",
    "cap1 = cv2.VideoCapture(super_sfm_movie)\n",
    "cap2 = cv2.VideoCapture(super_mvs_movie)\n",
    "\n",
    "# get resolution\n",
    "width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "i = 0\n",
    "\n",
    "pbar = tqdm(total=1200)\n",
    "\n",
    "while cap1.isOpened() and cap2.isOpened():\n",
    "\n",
    "    if i >= 1200:\n",
    "        break\n",
    "\n",
    "    frame = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "    frame1 = cap1.read()[1]\n",
    "    frame2 = cap2.read()[1]\n",
    "\n",
    "    if frame1 is None or frame2 is None:\n",
    "        break\n",
    "\n",
    "    if i == 0:   \n",
    "        for j in range(300):\n",
    "            frame = np.zeros((height, width, 3), np.uint8)\n",
    "            # move split view middle to left to right to middle\n",
    "            shift = np.sin(j/300 * 2* np.pi)\n",
    "            split = int(width/2 + shift * width/2)\n",
    "            frame[:, :split, :] = frame1[:, :split, :]\n",
    "            frame[:, split:, :] = frame2[:, split:, :]\n",
    "\n",
    "            # add vertical line\n",
    "            frame[:, split-1:split+1, :] = 0\n",
    "\n",
    "            # save frame\n",
    "            frame = add_text_to_frame(frame, location, base_model, super_model)\n",
    "            cv2.imwrite(os.path.join(data, \"movies\", f\"{name}{i}.png\"), frame)\n",
    "\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "    elif i == 600:\n",
    "        for j in range(300):\n",
    "            frame = np.zeros((height, width, 3), np.uint8)\n",
    "            # move split view middle to left to right to middle\n",
    "            shift = np.sin(j/300 * 2* np.pi)\n",
    "            split = int(width/2 + shift * width/2)\n",
    "            frame[:, :split, :] = frame1[:, :split, :]\n",
    "            frame[:, split:, :] = frame2[:, split:, :]\n",
    "\n",
    "            # add vertical line\n",
    "            frame[:, split-1:split+1, :] = 0\n",
    "\n",
    "            # save frame\n",
    "            frame = add_text_to_frame(frame, location, base_model, super_model)\n",
    "            cv2.imwrite(os.path.join(data, \"movies\", f\"{name}{i}.png\"), frame)\n",
    "\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "    else:\n",
    "        frame = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "        frame[:, :width//2, :] = frame1[:, :width//2, :]\n",
    "        frame[:, width//2:, :] = frame2[:, width//2:, :]\n",
    "\n",
    "        frame[:, width//2-1:width//2+1, :] = 0\n",
    "\n",
    "        # save frame\n",
    "        frame = add_text_to_frame(frame, location, base_model, super_model) \n",
    "        cv2.imwrite(os.path.join(data, \"movies\", f\"{name}{i}.png\"), frame)\n",
    "\n",
    "        i += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        \n",
    "cap1.release()\n",
    "cap2.release()\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "os.system(f\"ffmpeg -r 30 -i {os.path.join(data, 'movies', f'{name}%d.png')} -vcodec libx264 -crf 25  -pix_fmt yuv420p {os.path.join(data, 'movies', f'{name}.mp4')} -y\")\n",
    "\n",
    "# remove images\n",
    "for i in range(1200):\n",
    "    try:\n",
    "        os.remove(os.path.join(data, \"movies\", f\"{name}{i}.png\"))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadepth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
