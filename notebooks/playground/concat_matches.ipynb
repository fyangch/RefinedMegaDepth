{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Volumes/Extreme_SSD/MegaDepth/scenes/\"\n",
    "scene = \"0229\"\n",
    "features_dir = os.path.join(base_dir, scene, \"features\")\n",
    "matches_dir = os.path.join(base_dir, scene, \"matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(features_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_features = h5.File(os.path.join(features_dir, \"superpoint_max.h5\"), \"r\")\n",
    "super_matches = h5.File(os.path.join(matches_dir, \"superpoint_max-superglue-netvlad-50.h5\"), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loftr_features = h5.File(os.path.join(features_dir, \"loftr-netvlad-20.h5\"), \"r\")\n",
    "loftr_matches = h5.File(os.path.join(matches_dir, \"loftr-netvlad-20.h5\"), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_features = {\n",
    "    img: {\n",
    "        \"keypoints\": np.concatenate(\n",
    "            [super_features[img][\"keypoints\"], loftr_features[img][\"keypoints\"]], axis=0,\n",
    "        ),\n",
    "        \"scores\": np.concatenate(\n",
    "            [super_features[img][\"scores\"], loftr_features[img][\"score\"]], axis=0\n",
    "        ),\n",
    "        \"n_superpoint\": super_features[img][\"keypoints\"].shape[0],\n",
    "        \"n_loftr\": loftr_features[img][\"keypoints\"].shape[0],\n",
    "    }\n",
    "    for img in tqdm(super_features.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_kp_ds = h5.File(os.path.join(features_dir, \"ensemble.h5\"), \"w\")\n",
    "for img in tqdm(ensemble_features.keys()):\n",
    "    ens_kp_ds.create_group(img)\n",
    "    for k in ensemble_features[img].keys():\n",
    "        ens_kp_ds[img].create_dataset(k, data=ensemble_features[img][k])\n",
    "\n",
    "ens_kp_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_features = h5.File(os.path.join(features_dir, \"ensemble.h5\"), \"r\")\n",
    "features = ensemble_features[next(iter(ensemble_features.keys()))]\n",
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_matches = {}\n",
    "\n",
    "for img1 in tqdm(ensemble_features.keys()):\n",
    "    ensemble_matches[img1] = {}\n",
    "    for img2 in ensemble_features.keys():\n",
    "        if img1 == img2:\n",
    "            continue\n",
    "        ensemble_matches[img1][img2] = {}\n",
    "\n",
    "        # try:\n",
    "        #     super_m = super_matches[img1][img2]\n",
    "        # except KeyError:\n",
    "        #     super_m = super_matches[img2][img1]\n",
    "\n",
    "        # try:\n",
    "        #     loftr_m = loftr_matches[img1][img2]\n",
    "        # except KeyError:\n",
    "        #     loftr_m = loftr_matches[img2][img1]\n",
    "\n",
    "        if img1 in super_matches.keys() and img2 in super_matches[img1].keys():\n",
    "            super_m = super_matches[img1][img2]\n",
    "        elif img2 in super_matches.keys() and img1 in super_matches[img2].keys():\n",
    "            super_m = super_matches[img2][img1]\n",
    "        else:\n",
    "            super_m = None\n",
    "\n",
    "        if img1 in loftr_matches.keys() and img2 in loftr_matches[img1].keys():\n",
    "            loftr_m = loftr_matches[img1][img2]\n",
    "        elif img2 in loftr_matches.keys() and img1 in loftr_matches[img2].keys():\n",
    "            loftr_m = loftr_matches[img2][img1]\n",
    "        elif super_m is None:\n",
    "                continue\n",
    "\n",
    "        loftr_m = {\n",
    "            \"matches0\": np.array([]),\n",
    "            \"matching_scores0\": np.array([]),\n",
    "        }\n",
    "\n",
    "        ensemble_matches[img1][img2][\"matches0\"] = np.concatenate(\n",
    "            [\n",
    "                super_m[\"matches0\"],\n",
    "                np.array(loftr_m[\"matches0\"]) + ensemble_features[img1][\"n_superpoint\"],\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        ensemble_matches[img1][img2][\"matching_scores0\"] = np.concatenate(\n",
    "            [\n",
    "                super_m[\"matching_scores0\"],\n",
    "                loftr_m[\"matching_scores0\"],\n",
    "            ],\n",
    "            axis=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_matches_ds = h5.File(os.path.join(matches_dir, \"ensemble.h5\"), \"w\")\n",
    "for img1 in tqdm(ensemble_matches.keys()):\n",
    "    ens_matches_ds.create_group(img1)\n",
    "    for img2 in ensemble_matches[img1].keys():\n",
    "        ens_matches_ds[img1].create_group(img2)\n",
    "        for k in ensemble_matches[img1][img2].keys():\n",
    "            ens_matches_ds[img1][img2].create_dataset(\n",
    "                k, data=ensemble_matches[img1][img2][k]\n",
    "            )\n",
    "\n",
    "ens_matches_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from hloc import reconstruction\n",
    "\n",
    "reconstruction.main(\n",
    "    sfm_dir=Path(os.path.join(base_dir, scene, \"sparse\", \"ensemble\")),\n",
    "    image_dir=Path(os.path.join(base_dir, scene, \"images\")),\n",
    "    pairs=Path(os.path.join(matches_dir, \"retrieval\", \"netvlad-50.txt\")),\n",
    "    features=Path(os.path.join(features_dir, \"ensemble.h5\")),\n",
    "    matches=Path(os.path.join(matches_dir, \"ensemble.h5\")),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadepth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
